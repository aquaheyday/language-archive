# 📐 머신러닝을 위한 선형대수 정리

머신러닝과 딥러닝의 수학적 기반 중 가장 중요한 축 중 하나가 **선형대수(Linear Algebra)** 입니다.  
데이터는 벡터로 표현되고, 모델은 행렬 연산으로 학습되며, 뉴럴 네트워크는 결국 **다차원 선형변환의 조합**으로 구성됩니다.

---

## 📌 핵심 용어 정리

| 용어 | 설명 | 예시 |
|------|------|------|
| 스칼라 (Scalar) | 하나의 숫자 | 3, -1.5, 0 |
| 벡터 (Vector) | 숫자의 나열 (1차원) | [2, 4, -1] |
| 행렬 (Matrix) | 숫자의 2차원 배열 | \[\[1, 2\], \[3, 4\]\] |
| 텐서 (Tensor) | 다차원 배열 (3차원 이상 포함) | 이미지 데이터 등 |

---

## 📌 벡터(Vector)

- 방향성과 크기를 가지는 1차원 수치 집합
- 머신러닝에서는 **입력 데이터, 가중치 등 거의 모든 요소가 벡터로 표현**됨

```plaintext
예: x = [1, 2, 3]
```

### 주요 연산

- 덧셈/뺄셈: 같은 차원끼리 요소별 연산  
- 스칼라 곱: 모든 원소에 하나의 숫자 곱셈  
- 내적 (Dot Product):  
  ```plaintext
  [a, b] · [c, d] = a*c + b*d
  ```

---

## 📌 행렬(Matrix)

- 2차원 형태의 수 데이터 집합 (n × m)
- **데이터셋, 가중치, 이미지** 등을 표현

```plaintext
A = [[1, 2],
     [3, 4]]
```

### 주요 연산

- 전치(Transpose): 행과 열을 뒤바꿈  
  ```plaintext
  Aᵗ = [[1, 3],
        [2, 4]]
  ```

- 행렬 곱: A(m×n) × B(n×p) = C(m×p)

---

## 📌 선형변환 (Linear Transformation)

- 행렬 곱은 **공간을 변형**하는 효과를 가짐 (스케일, 회전, 반사 등)
- 딥러닝에서 각 레이어는 선형변환 + 비선형함수로 구성됨

```plaintext
y = Wx + b
```

---

## 📌 고유값(Eigenvalue)과 고유벡터(Eigenvector)

- 어떤 행렬 A에 대해, 다음을 만족하는 v, λ가 존재:
  ```plaintext
  A * v = λ * v
  ```
- PCA, 추천 시스템, 자연어 임베딩 등에서 핵심 역할

---

## 📌 응용 예시

- **PCA (주성분 분석)**: 고유벡터를 통해 데이터 차원을 축소  
- **신경망 연산**: 입력 벡터 * 가중치 행렬 → 출력 벡터  
- **코사인 유사도**: 두 벡터 사이 각도를 통해 유사도 계산
